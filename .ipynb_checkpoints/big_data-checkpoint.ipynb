{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import maxabs_scale, normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artist_lookup = pickle.load(open('artist_lookup.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_lookup = pickle.load(open('user_lookup.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "profiles_data = pd.read_csv('profiles.csv')\n",
    "user_id_lookup = profiles_data.groupby('user').groups\n",
    "def get_user_id(user_hash):\n",
    "    return user_id_lookup[user_hash][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artists_data = pd.read_csv('artists.csv')\n",
    "artist_id_lookup = artists_data.groupby('artist').groups\n",
    "def get_artist_id(artist_hash):\n",
    "    return artist_id_lookup[artist_hash][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_extraction(training_data, num_examples=None):\n",
    "        \n",
    "    start = time.clock()\n",
    "    if not num_examples:\n",
    "        num_examples = len(training_data)\n",
    "    \n",
    "    list_of_features = np.empty(num_examples, dtype=dict)\n",
    "\n",
    "    example_i = 0\n",
    "    for _, row in training_data[:num_examples].iterrows():\n",
    "        \n",
    "        features = {}\n",
    "\n",
    "        # ************************************************\n",
    "        # Features for the user, independent of the artist\n",
    "        user_features = user_lookup[row['user']]\n",
    "        \n",
    "#         features['user_id_{}'.format(get_user_id(row['user']))] = 1\n",
    "        \n",
    "        features['user_sex_{}'.format(user_features['sex'])] = 1\n",
    "\n",
    "        # Seems unlikely to improve model if included raw\n",
    "        user_cn = user_features['cn']\n",
    "        user_region = user_features['region']\n",
    "        \n",
    "        user_age = user_features['age']\n",
    "        features['user_age'] = user_age\n",
    "        \n",
    "        features['user_avg_plays'] = user_features['average_plays']\n",
    "        features['user_num_artists'] = user_features['num_artists']\n",
    "        features['user_median_plays'] = user_features['user_median_plays']\n",
    "        features['user_avg_log_plays'] = user_features['average_log_plays']\n",
    "        \n",
    "        user_popularity = user_features['average_popularity']\n",
    "        features['user_avg_popularity'] = user_popularity\n",
    "        \n",
    "        features['user_avg_sub_global_avg'] = user_features['user_avg_sub_global_avg']\n",
    "        \n",
    "#         features['user_fav_genre_{}'.format(user_features['favorite_genres'].most_common(1)[0][0])] = 1\n",
    "        \n",
    "        # ****************************************\n",
    "        # Just the artist, independent of the user\n",
    "        artist_features = artist_lookup[row['artist']]\n",
    "        \n",
    "#         features['artist_id_{}'.format(get_artist_id(row['artist']))] = 1\n",
    "        \n",
    "        artist_popularity = artist_features['popularity']\n",
    "        features['artist_spotify_popularity'] = artist_popularity\n",
    "        \n",
    "        features['artist_avg_sub_global_avg'] = artist_features['artist_avg_sub_global_avg']\n",
    "        \n",
    "        artist_age = artist_features['average_age']\n",
    "        features['artist_average_listener_age'] = artist_age\n",
    "        \n",
    "        prop_male, prop_female, prop_unknown = artist_features['m'], artist_features['f'], artist_features['u']\n",
    "\n",
    "        artist_num_listeners = artist_features['total_listeners']\n",
    "        features['artist_num_listeners'] = artist_num_listeners\n",
    "        \n",
    "        features['artist_avg_plays'] = artist_features['avg_plays'] \n",
    "        features['artist_median_plays'] = artist_features['median_plays']\n",
    "        features['artist_avg_log_plays'] = artist_features['log_average_plays']\n",
    "        \n",
    "        features['artist_genre_{}'.format(artist_features['genre_id'])] = 1\n",
    "        \n",
    "        \n",
    "        # **********************************************\n",
    "        # Features dependent on both the artist and user\n",
    "        features['share_cn'] = 1 if user_cn in [cn for cn, _ in artist_features['fan_cns'].most_common(5)] else 0\n",
    "        features['share_prob_user_from_region'] = artist_features['fan_cns'][user_cn] / np.sum(artist_features['fan_cns'].values())\n",
    "        features['share_prob_user_from_country'] = artist_features['fan_regions'][user_region] / np.sum(artist_features['fan_regions'].values())\n",
    "        \n",
    "        # TODO: Get percentage of fans in same region, and percentage in same country.\n",
    "            \n",
    "        if abs(user_age - artist_age) < 2:\n",
    "            features['share_age'] = 1\n",
    "            \n",
    "        features['diff_age'] = abs(user_age - artist_age)  \n",
    "            \n",
    "        fav_user_genres = set([genre for genre, _ in user_features['favorite_genres'].most_common(4)])\n",
    "        artist_genres = set(artist_features['genres'])\n",
    "        shared_genres = fav_user_genres & artist_genres\n",
    "        g_count = 0\n",
    "        for g in shared_genres:  \n",
    "            g_count += user_features['favorite_genres'][g]\n",
    "        features['share_genre'] = g_count\n",
    "        # TODO Maybe also encode the actual genres? \n",
    "#         features['share_genre'] = 1 if len(shared_genres) > 0 else 0\n",
    "        \n",
    "        if abs(user_popularity - artist_popularity) < 5:\n",
    "            features['share_popularity'] = 1\n",
    "            \n",
    "        features['diff_popularity'] = abs(user_popularity - artist_popularity)   \n",
    "\n",
    "        features['share_prob_user_listens_by_gender_{}'.format(user_features['sex'])] = artist_features[user_features['sex']]\n",
    "            \n",
    "        list_of_features[example_i] = features\n",
    "        example_i += 1\n",
    "        \n",
    "    print(time.clock() - start)\n",
    "    return list_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437.083219\n"
     ]
    }
   ],
   "source": [
    "train_n = 4000000\n",
    "feature_list = feature_extraction(train[:train_n])\n",
    "Y = np.array(train[:train_n]['plays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(feature_list, open('trainer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = DictVectorizer()\n",
    "X = v.fit(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "available_features = v.get_feature_names()\n",
    "support = [1 for _ in range(len(available_features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(available_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "possible_features = set(available_features)\n",
    "\n",
    "undesired_features = {\n",
    "    'artist_average_listener_age',\n",
    "    'artist_avg_plays',\n",
    "    'artist_avg_sub_global_avg',\n",
    "    'share_age',\n",
    "    'share_popularity',\n",
    "    'user_age',\n",
    "    'user_avg_plays',\n",
    "    'user_avg_sub_global_avg',\n",
    "}\n",
    "\n",
    "actual_features = possible_features - undesired_features\n",
    "\n",
    "support = [0 for _ in range(len(possible_features))]\n",
    "for i, feature in enumerate(possible_features):\n",
    "    if feature in actual_features:\n",
    "        support[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v.restrict(support)\n",
    "X_restricted = v.transform(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000000, 40)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_restricted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LR(X, Y, samples):\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:samples], Y[:samples], test_size=2)\n",
    "    \n",
    "    X_train = maxabs_scale(X_train)\n",
    "    X_test = maxabs_scale(X_test)\n",
    "    \n",
    "    clf = LinearRegression(n_jobs=-1)\n",
    "    clf.fit(X_train, np.log(y_train))\n",
    "    \n",
    "    y_hat = clf.predict(X_test)\n",
    "    y_hat_train = clf.predict(X_train)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, np.exp(y_hat))\n",
    "    train_mae = mean_absolute_error(y_train, np.exp(y_hat_train))\n",
    "    \n",
    "    print('Testing:')\n",
    "    print(test_mae)\n",
    "    \n",
    "    print('Training:')\n",
    "    print(train_mae)\n",
    "    \n",
    "    print('Time:')\n",
    "    print(time.clock() - start)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "6559.90448321\n",
      "Training:\n",
      "130.589052999\n",
      "Time:\n",
      "34.582461\n"
     ]
    }
   ],
   "source": [
    "slf_to_submit = LR(X_restricted, Y, 4000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(slf_to_submit, open('lr_final.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RF(X, Y, samples, depth=None):\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:samples], Y[:samples], test_size=0.33)\n",
    "    \n",
    "    X_train = maxabs_scale(X_train)\n",
    "    X_test = maxabs_scale(X_test)\n",
    "    \n",
    "    clf = RandomForestRegressor(n_estimators=40, n_jobs=-1, max_depth=depth)\n",
    "    clf.fit(X_train, np.log(y_train))\n",
    "    \n",
    "    y_hat = clf.predict(X_test)\n",
    "    y_hat_train = clf.predict(X_train)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, np.exp(y_hat))\n",
    "    train_mae = mean_absolute_error(y_train, np.exp(y_hat_train))\n",
    "    \n",
    "    print('Testing:')\n",
    "    print(test_mae)\n",
    "    \n",
    "    print('Training:')\n",
    "    print(train_mae)\n",
    "    \n",
    "    print('Time:')\n",
    "    print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "197.695324592\n",
      "Training:\n",
      "62.1124184893\n",
      "Time:\n",
      "121.641689\n"
     ]
    }
   ],
   "source": [
    "RF(X_restricted, Y, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "138.068898838\n",
      "Training:\n",
      "60.7693671304\n",
      "Time:\n",
      "296.966475\n"
     ]
    }
   ],
   "source": [
    "RF(X_restricted, Y, 50000, depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "207.044377488\n",
      "Training:\n",
      "62.8956469081\n",
      "Time:\n",
      "116.359481\n"
     ]
    }
   ],
   "source": [
    "RF(X_restricted, Y, 30000, depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LR(X, Y, samples):\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:samples], Y[:samples], test_size=0.33)\n",
    "    \n",
    "    X_train = maxabs_scale(X_train)\n",
    "    X_test = maxabs_scale(X_test)\n",
    "    \n",
    "    clf = LinearRegression(n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = clf.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_hat)\n",
    "    print(mae)\n",
    "    \n",
    "    print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.292537955\n",
      "1.77469\n"
     ]
    }
   ],
   "source": [
    "LR(X_restricted, Y, 400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
