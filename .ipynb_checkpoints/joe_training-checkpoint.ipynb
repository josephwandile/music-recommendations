{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import maxabs_scale, normalize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "artist_lookup = pickle.load(open('artist_lookup.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "user_lookup = pickle.load(open('user_lookup.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "profiles_data = pd.read_csv('profiles.csv')\n",
    "user_id_lookup = profiles_data.groupby('user').groups\n",
    "def get_user_id(user_hash):\n",
    "    return user_id_lookup[user_hash][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_data = pd.read_csv('artists.csv')\n",
    "artist_id_lookup = artists_data.groupby('artist').groups\n",
    "def get_artist_id(artist_hash):\n",
    "    return artist_id_lookup[artist_hash][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def feature_extraction(training_data, num_examples=None):\n",
    "        \n",
    "    start = time.clock()\n",
    "    if not num_examples:\n",
    "        num_examples = len(training_data)\n",
    "    \n",
    "    list_of_features = np.empty(num_examples, dtype=dict)\n",
    "\n",
    "    example_i = 0\n",
    "    for _, row in training_data[:num_examples].iterrows():\n",
    "        \n",
    "        features = {}\n",
    "\n",
    "        # ************************************************\n",
    "        # Features for the user, independent of the artist\n",
    "        user_features = user_lookup[row['user']]\n",
    "        \n",
    "#         features['user_id_{}'.format(get_user_id(row['user']))] = 1\n",
    "        \n",
    "        features['user_sex_{}'.format(user_features['sex'])] = 1\n",
    "\n",
    "        # Seems unlikely to improve model if included raw\n",
    "        user_cn = user_features['cn']\n",
    "        user_region = user_features['region']\n",
    "        \n",
    "        user_age = user_features['age']\n",
    "        features['user_age'] = user_age\n",
    "        \n",
    "        features['user_avg_plays'] = user_features['average_plays']\n",
    "        features['user_num_artists'] = user_features['num_artists']\n",
    "        features['user_median_plays'] = user_features['user_median_plays']\n",
    "        features['user_avg_log_plays'] = user_features['average_log_plays']\n",
    "        \n",
    "        user_popularity = user_features['average_popularity']\n",
    "        features['user_avg_popularity'] = user_popularity\n",
    "        \n",
    "        features['user_avg_sub_global_avg'] = user_features['user_avg_sub_global_avg']\n",
    "        \n",
    "#         features['user_fav_genre_{}'.format(user_features['favorite_genres'].most_common(1)[0][0])] = 1\n",
    "        \n",
    "        # ****************************************\n",
    "        # Just the artist, independent of the user\n",
    "        artist_features = artist_lookup[row['artist']]\n",
    "        \n",
    "#         features['artist_id_{}'.format(get_artist_id(row['artist']))] = 1\n",
    "        \n",
    "        artist_popularity = artist_features['popularity']\n",
    "        features['artist_spotify_popularity'] = artist_popularity\n",
    "        \n",
    "        features['artist_avg_sub_global_avg'] = artist_features['artist_avg_sub_global_avg']\n",
    "        \n",
    "        artist_age = artist_features['average_age']\n",
    "        features['artist_average_listener_age'] = artist_age\n",
    "        \n",
    "        prop_male, prop_female, prop_unknown = artist_features['m'], artist_features['f'], artist_features['u']\n",
    "\n",
    "        artist_num_listeners = artist_features['total_listeners']\n",
    "        features['artist_num_listeners'] = artist_num_listeners\n",
    "        \n",
    "        features['artist_avg_plays'] = artist_features['avg_plays'] \n",
    "        features['artist_median_plays'] = artist_features['median_plays']\n",
    "        features['artist_avg_log_plays'] = artist_features['log_average_plays']\n",
    "        \n",
    "        features['artist_genre_{}'.format(artist_features['genre_id'])] = 1\n",
    "        \n",
    "        \n",
    "        # **********************************************\n",
    "        # Features dependent on both the artist and user\n",
    "        features['share_cn'] = 1 if user_cn in [cn for cn, _ in artist_features['fan_cns'].most_common(5)] else 0\n",
    "        features['share_prob_user_from_region'] = artist_features['fan_cns'][user_cn] / np.sum(artist_features['fan_cns'].values())\n",
    "        features['share_prob_user_from_country'] = artist_features['fan_regions'][user_region] / np.sum(artist_features['fan_regions'].values())\n",
    "        \n",
    "        # TODO: Get percentage of fans in same region, and percentage in same country.\n",
    "            \n",
    "        if abs(user_age - artist_age) < 2:\n",
    "            features['share_age'] = 1\n",
    "            \n",
    "        features['diff_age'] = abs(user_age - artist_age)  \n",
    "            \n",
    "        fav_user_genres = set([genre for genre, _ in user_features['favorite_genres'].most_common(4)])\n",
    "        artist_genres = set(artist_features['genres'])\n",
    "        shared_genres = fav_user_genres & artist_genres\n",
    "        g_count = 0\n",
    "        for g in shared_genres:  \n",
    "            g_count += user_features['favorite_genres'][g]\n",
    "        features['share_genre'] = g_count\n",
    "        # TODO Maybe also encode the actual genres? \n",
    "#         features['share_genre'] = 1 if len(shared_genres) > 0 else 0\n",
    "        \n",
    "        if abs(user_popularity - artist_popularity) < 5:\n",
    "            features['share_popularity'] = 1\n",
    "            \n",
    "        features['diff_popularity'] = abs(user_popularity - artist_popularity)   \n",
    "\n",
    "        features['share_prob_user_listens_by_gender_{}'.format(user_features['sex'])] = artist_features[user_features['sex']]\n",
    "            \n",
    "        list_of_features[example_i] = features\n",
    "        example_i += 1\n",
    "        \n",
    "    print(time.clock() - start)\n",
    "    return list_of_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-e90d44ad7d03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# feature_list = feature_extraction(train[:train_n])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Y = np.array(train[:train_n]['plays'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeature_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plays'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-825b6c91f47f>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(training_data, num_examples)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Features dependent on both the artist and user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'share_cn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muser_cn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martist_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fan_cns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'share_prob_user_from_region'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martist_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fan_cns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_cn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fan_cns'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'share_prob_user_from_country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martist_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fan_regions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_region\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fan_regions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1707\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 1709\u001b[0;31m                                 out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m   1710\u001b[0m         \u001b[0;31m# NOTE: Dropping the keepdims parameters here...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     return um.add.reduce(a, axis=axis, dtype=dtype,\n\u001b[0;32m---> 25\u001b[0;31m                             out=out, keepdims=keepdims)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_n = 1000\n",
    "# feature_list = feature_extraction(train[:train_n])\n",
    "#Y = np.array(train[:train_n]['plays'])\n",
    "feature_list = feature_extraction(train)\n",
    "Y = np.array(train['plays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(feature_list, open('trainer.pkl', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v = DictVectorizer()\n",
    "X = v.fit(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "available_features = v.get_feature_names()\n",
    "support = [1 for _ in range(len(available_features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "possible_features = set(available_features)\n",
    "\n",
    "undesired_features = {\n",
    "    'artist_average_listener_age',\n",
    "    'artist_avg_plays',\n",
    "    'artist_avg_sub_global_avg',\n",
    "    'share_age',\n",
    "    'share_popularity',\n",
    "    'user_age',\n",
    "    'user_avg_plays',\n",
    "    'user_avg_sub_global_avg',\n",
    "}\n",
    "\n",
    "actual_features = possible_features - undesired_features\n",
    "\n",
    "support = [0 for _ in range(len(possible_features))]\n",
    "for i, feature in enumerate(possible_features):\n",
    "    if feature in actual_features:\n",
    "        support[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "v.restrict(support)\n",
    "X_restricted = v.transform(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist_average_listener_age',\n",
       " 'artist_avg_log_plays',\n",
       " 'artist_avg_sub_global_avg',\n",
       " 'artist_genre_0',\n",
       " 'artist_genre_1',\n",
       " 'artist_genre_10',\n",
       " 'artist_genre_11',\n",
       " 'artist_genre_12',\n",
       " 'artist_genre_13',\n",
       " 'artist_genre_14',\n",
       " 'artist_genre_15',\n",
       " 'artist_genre_16',\n",
       " 'artist_genre_17',\n",
       " 'artist_genre_18',\n",
       " 'artist_genre_19',\n",
       " 'artist_genre_2',\n",
       " 'artist_genre_3',\n",
       " 'artist_genre_5',\n",
       " 'artist_genre_6',\n",
       " 'artist_genre_7',\n",
       " 'artist_genre_8',\n",
       " 'artist_median_plays',\n",
       " 'artist_num_listeners',\n",
       " 'artist_spotify_popularity',\n",
       " 'diff_age',\n",
       " 'diff_popularity',\n",
       " 'share_age',\n",
       " 'share_cn',\n",
       " 'share_genre',\n",
       " 'share_popularity',\n",
       " 'share_prob_user_from_country',\n",
       " 'share_prob_user_from_region',\n",
       " 'share_prob_user_listens_by_gender_u',\n",
       " 'user_avg_log_plays',\n",
       " 'user_avg_plays',\n",
       " 'user_avg_popularity',\n",
       " 'user_median_plays',\n",
       " 'user_sex_f',\n",
       " 'user_sex_m',\n",
       " 'user_sex_u']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 38)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_restricted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LR(X, Y, samples):\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:samples], Y[:samples], test_size=0.33)\n",
    "    \n",
    "#     X_train = maxabs_scale(X_train)\n",
    "#     X_test = maxabs_scale(X_test)\n",
    "    \n",
    "    clf = LinearRegression(n_jobs=-1)\n",
    "    clf.fit(X_train, np.log(y_train))\n",
    "    \n",
    "    y_hat = clf.predict(X_test)\n",
    "    y_hat_train = clf.predict(X_train)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, np.exp(y_hat))\n",
    "    train_mae = mean_absolute_error(y_train, np.exp(y_hat_train))\n",
    "    \n",
    "    print('Testing:')\n",
    "    print(test_mae)\n",
    "    \n",
    "    print('Training:')\n",
    "    print(train_mae)\n",
    "    \n",
    "    print('Time:')\n",
    "    print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "142615320.898\n",
      "Training:\n",
      "1.71119031447e+13\n",
      "Time:\n",
      "1.925752\n"
     ]
    }
   ],
   "source": [
    "LR(X_restricted, Y, 400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def RF(X, Y, samples, depth=None):\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:samples], Y[:samples], test_size=0.33)\n",
    "    \n",
    "    X_train = maxabs_scale(X_train)\n",
    "    X_test = maxabs_scale(X_test)\n",
    "    \n",
    "    clf = RandomForestRegressor(n_estimators=40, n_jobs=-1, max_depth=depth)\n",
    "    clf.fit(X_train, np.log(y_train))\n",
    "    \n",
    "    y_hat = clf.predict(X_test)\n",
    "    y_hat_train = clf.predict(X_train)\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, np.exp(y_hat))\n",
    "    train_mae = mean_absolute_error(y_train, np.exp(y_hat_train))\n",
    "    \n",
    "    print('Testing:')\n",
    "    print(test_mae)\n",
    "    \n",
    "    print('Training:')\n",
    "    print(train_mae)\n",
    "    \n",
    "    print('Time:')\n",
    "    print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "197.695324592\n",
      "Training:\n",
      "62.1124184893\n",
      "Time:\n",
      "121.641689\n"
     ]
    }
   ],
   "source": [
    "RF(X_restricted, Y, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "138.068898838\n",
      "Training:\n",
      "60.7693671304\n",
      "Time:\n",
      "296.966475\n"
     ]
    }
   ],
   "source": [
    "RF(X_restricted, Y, 50000, depth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\n",
      "207.044377488\n",
      "Training:\n",
      "62.8956469081\n",
      "Time:\n",
      "116.359481\n"
     ]
    }
   ],
   "source": [
    "RF(X_restricted, Y, 30000, depth=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def LR(X, Y, samples):\n",
    "    \n",
    "    start = time.clock()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[:samples], Y[:samples], test_size=0.33)\n",
    "    \n",
    "    X_train = maxabs_scale(X_train)\n",
    "    X_test = maxabs_scale(X_test)\n",
    "    \n",
    "    clf = LinearRegression(n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat = clf.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_hat)\n",
    "    print(mae)\n",
    "    \n",
    "    print(time.clock() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.292537955\n",
      "1.77469\n"
     ]
    }
   ],
   "source": [
    "LR(X_restricted, Y, 400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
